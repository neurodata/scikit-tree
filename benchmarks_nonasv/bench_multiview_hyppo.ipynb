{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37f540f-444b-4040-9bba-c945e6b65bfb",
   "metadata": {},
   "source": [
    "# Benchmarking Analysis for Multiview Hypothesis Testers\n",
    "\n",
    "Here, we are interested in analyzing the performance of using multi-view trees in the presence\n",
    "of two views of data, when one of the datasets has a significantly greater number of dimensions.\n",
    "\n",
    "For example, in liquid biopsies from cancer patients, we might obtain features describing the\n",
    "fragment lengths of DNA found, or a description of the fragment ends (e.g. what is the ratio of base-pairs\n",
    "found at the end). These might have wildly different dimensionalities like 1000 vs 10,000 if we consider\n",
    "different levels of complexities of each of these biological characteristics.\n",
    "\n",
    "So we want a hypothesis test that is i) aware of the fact that ``X`` is comprised of two feature-sets, and ii)\n",
    "is able to handle wildly different dimensionalities in each of the feature-sets with sufficient power\n",
    "and type-I error rate to provide useful answers to cancer biomarker hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cf4cc8-098d-4810-ad70-0e4234fef660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "\n",
    "from sktree import HonestForestClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sktree.stats import (\n",
    "    FeatureImportanceForestClassifier,\n",
    "    FeatureImportanceForestRegressor,\n",
    "    PermutationForestRegressor,\n",
    ")\n",
    "\n",
    "import mvlearn\n",
    "from mvlearn.datasets import make_gaussian_mixture\n",
    "\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20fdbc-8a2e-48b8-a52d-1c4696562e5c",
   "metadata": {},
   "source": [
    "# Simulate data with varying dimensionality\n",
    "\n",
    "Here, we will implement a function to simulate data with a varying number of dimensions in the second view.\n",
    "\n",
    "We will implement a simulation that leverages two views stemming from the graphical model:\n",
    "\n",
    "$(X1 \\rightarrow Y \\leftarrow X2; X1 \\leftrightarrow X2)$\n",
    "\n",
    "or\n",
    "\n",
    "$(X1 \\rightarrow Y \\leftarrow X2)$\n",
    "\n",
    "where X1 and X2 are two views and Y is the target variable. The bidirected edge between X1 and X2 is just to allow the two views to\n",
    "be potentially correlated. \n",
    "\n",
    "We will also use the package `mvlearn` to simulate a two-view dataset using their `make_gaussian_mixture` function (https://mvlearn.github.io/references/datasets.html#data-simulator). This simulates a ``X`` and a ``y``, and then applies a transformation on ``X``, which produces the second view. This stems from the graphical model:\n",
    "\n",
    "$(X1 \\rightarrow Y \\leftarrow X2; X1 \\rightarrow X2)$\n",
    "\n",
    "where X1 is the original dataset and X2 is the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20692bea-a3f9-43b1-ab20-dfbc7aa25f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiview_classification(\n",
    "    n_samples=100,\n",
    "    n_features_1=100,\n",
    "    n_features_2=10000,\n",
    "    cluster_std_first=2.0,\n",
    "    cluster_std_second=5.0,\n",
    "    X0_first=None,\n",
    "    y0=None,\n",
    "    X1_first=None,\n",
    "    y1=None,\n",
    "    seed=None,\n",
    "):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    if X0_first is None and y0 is None:\n",
    "        # Create a high-dimensional multiview dataset with a low-dimensional informative\n",
    "        # subspace in one view of the dataset.\n",
    "        X0_first, y0 = make_blobs(\n",
    "            n_samples=n_samples,\n",
    "            cluster_std=cluster_std_first,\n",
    "            n_features=n_features_1,\n",
    "            random_state=rng.integers(1, 10000),\n",
    "            centers=1,\n",
    "        )\n",
    "\n",
    "        X1_first, y1 = make_blobs(\n",
    "            n_samples=n_samples,\n",
    "            cluster_std=cluster_std_second,\n",
    "            n_features=n_features_1,\n",
    "            random_state=rng.integers(1, 10000),\n",
    "            centers=1,\n",
    "        )\n",
    "    y1[:] = 1\n",
    "    X0 = np.concatenate(\n",
    "        [X0_first, rng.standard_normal(size=(n_samples, n_features_2))], axis=1\n",
    "    )\n",
    "    X1 = np.concatenate(\n",
    "        [X1_first, rng.standard_normal(size=(n_samples, n_features_2))], axis=1\n",
    "    )\n",
    "    X = np.vstack((X0, X1))\n",
    "    y = np.hstack((y0, y1)).T\n",
    "\n",
    "    X = X + rng.standard_normal(size=X.shape)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599d1cd-b178-426a-9494-5ddf11174b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "# -------------\n",
    "# We simulate a 2-view dataset with both views containing informative low-dimensional features.\n",
    "# The first view has five dimensions, while the second view will vary from five to a thousand\n",
    "# dimensions. The sample-size will be kept fixed, so we can compare the performance of\n",
    "# regular Random forests with Multi-view Random Forests.\n",
    "\n",
    "n_samples = 500\n",
    "n_features_views = np.linspace(5, 20000, 5).astype(int)\n",
    "\n",
    "datasets = []\n",
    "\n",
    "# make the signal portions of the dataset\n",
    "X0_first, y0 = make_blobs(\n",
    "    n_samples=n_samples,\n",
    "    cluster_std=5.0,\n",
    "    n_features=5,\n",
    "    random_state=rng.integers(1, 10000),\n",
    "    centers=1,\n",
    ")\n",
    "X1_first, y1 = make_blobs(\n",
    "    n_samples=n_samples,\n",
    "    cluster_std=10.0,\n",
    "    n_features=5,\n",
    "    random_state=rng.integers(1, 10000),\n",
    "    centers=1,\n",
    ")\n",
    "\n",
    "# increasingly add noise dimensions to the second view\n",
    "for idx, n_features in enumerate(n_features_views):\n",
    "    X, y = make_multiview_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features_1=5,\n",
    "        n_features_2=n_features,\n",
    "        cluster_std_first=5.0,\n",
    "        cluster_std_second=10.0,\n",
    "        # X0_first=X0_first, y0=y0,\n",
    "        # X1_first=X1_first, y1=y1,\n",
    "        seed=seed + idx,\n",
    "    )\n",
    "    datasets.append((X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktree",
   "language": "python",
   "name": "sktree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
