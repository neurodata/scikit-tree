{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a2827-69dc-4c71-ae75-3f6216622916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef3237f-3d4c-45d5-89ec-d03e65edd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ebb1f5-eeee-42fd-9b57-24a8796e7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "from sklearn.datasets import (\n",
    "    make_blobs,\n",
    "    make_classification,\n",
    "    make_sparse_spd_matrix,\n",
    "    make_spd_matrix,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier as skDecisionTreeClassifier\n",
    "\n",
    "from sktree import HonestForestClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sktree.datasets.multiview import make_gaussian_mixture, make_joint_factor_model\n",
    "from sktree.stats import (\n",
    "    FeatureImportanceForestClassifier,\n",
    "    FeatureImportanceForestRegressor,\n",
    "    PermutationForestRegressor,\n",
    ")\n",
    "from sktree.tree import DecisionTreeClassifier, MultiViewDecisionTreeClassifier\n",
    "\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5878476-1502-4a20-8984-864e9f5e3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3aeaca-31ad-4e26-a234-b4157b335781",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = \"sqrt\"\n",
    "n_estimators = 500\n",
    "n_jobs = -1\n",
    "test_size = 0.2\n",
    "max_fpr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa291da-0583-4f4c-81a3-b55d0ae9f574",
   "metadata": {},
   "source": [
    "# Data-generating model with a copy of the feature-set\n",
    "\n",
    "Here, we say X = (X1, X1), where X1 is a feature-set that may be informative of Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0a48d8-c932-4e75-95e0-07c24cca8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "noise_dims = 80\n",
    "n_features = 100 - noise_dims\n",
    "n_features_2 = 10000 - noise_dims\n",
    "\n",
    "# max_features = 0.3\n",
    "\n",
    "n_repeats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b05eb505-54d6-4253-84aa-86676bc262ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 100]\n",
      "(200, 100) 0.505\n",
      "(200, 200)\n",
      "[100, 200]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=100,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    class_sep=2.0,\n",
    "    flip_y=0.05,\n",
    "    shuffle=False,\n",
    "    random_state=seed,\n",
    ")\n",
    "n_features_ends = [20, X.shape[1]]\n",
    "print(n_features_ends)\n",
    "print(X.shape, np.sum(y) / n_samples)\n",
    "\n",
    "X = np.hstack((X, X))\n",
    "print(X.shape)\n",
    "\n",
    "n_features_ends = [X.shape[1] // 2, X.shape[1]]\n",
    "print(n_features_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68f6f39-ff59-47a1-be53-f129d0418a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10085299540085102 0.08304276713486813 0.13011074840498627\n",
      "0.000999000999000999 0.000999000999000999 0.005994005994005994\n"
     ]
    }
   ],
   "source": [
    "est = FeatureImportanceForestClassifier(\n",
    "    estimator=HonestForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "            feature_set_ends=n_features_ends,\n",
    "            apply_max_features_per_feature_set=True,\n",
    "        ),\n",
    "        random_state=seed,\n",
    "        honest_fraction=0.5,\n",
    "        n_jobs=n_jobs,\n",
    "    ),\n",
    "    random_state=seed,\n",
    "    test_size=test_size,\n",
    "    permute_per_tree=False,\n",
    "    sample_dataset_per_tree=False,\n",
    ")\n",
    "\n",
    "est_mv_old = FeatureImportanceForestClassifier(\n",
    "    estimator=HonestForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "            feature_set_ends=n_features_ends,\n",
    "            apply_max_features_per_feature_set=False,\n",
    "        ),\n",
    "        random_state=seed,\n",
    "        honest_fraction=0.5,\n",
    "        n_jobs=n_jobs,\n",
    "    ),\n",
    "    random_state=seed,\n",
    "    test_size=test_size,\n",
    "    permute_per_tree=False,\n",
    "    sample_dataset_per_tree=False,\n",
    ")\n",
    "\n",
    "est_rf = FeatureImportanceForestClassifier(\n",
    "    estimator=HonestForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        tree_estimator=DecisionTreeClassifier(),\n",
    "        # tree_estimator=skDecisionTreeClassifier(),\n",
    "        random_state=seed,\n",
    "        honest_fraction=0.5,\n",
    "        n_jobs=n_jobs,\n",
    "    ),\n",
    "    random_state=seed,\n",
    "    test_size=test_size,\n",
    "    permute_per_tree=False,\n",
    "    sample_dataset_per_tree=False,\n",
    ")\n",
    "\n",
    "# compute the statistic and pvalue when we permute the first feature-set\n",
    "covariate_index = np.arange(0, n_features_ends[0])\n",
    "# print(covariate_index)\n",
    "stat, pvalue = est.test(\n",
    "    X,\n",
    "    y,\n",
    "    covariate_index=covariate_index,\n",
    "    metric=\"mi\",\n",
    "    n_repeats=1000,\n",
    "    # max_fpr=max_fpr\n",
    ")\n",
    "stat_old, pvalue_old = est_mv_old.test(\n",
    "    X,\n",
    "    y,\n",
    "    covariate_index=covariate_index,\n",
    "    metric=\"mi\",\n",
    "    n_repeats=1000,\n",
    "    # max_fpr=max_fpr\n",
    ")\n",
    "stat_rf, pvalue_rf = est_rf.test(\n",
    "    X,\n",
    "    y,\n",
    "    metric=\"mi\",\n",
    "    n_repeats=1000,\n",
    "    # max_fpr=max_fpr\n",
    ")\n",
    "\n",
    "print(stat, stat_rf, stat_old)\n",
    "print(pvalue, pvalue_rf, pvalue_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d8de9-3440-41e8-aeb1-83f467eee01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktree",
   "language": "python",
   "name": "sktree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
