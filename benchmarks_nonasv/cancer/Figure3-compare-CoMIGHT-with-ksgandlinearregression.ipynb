{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4127d9dd-2851-409d-b709-420e24183431",
   "metadata": {},
   "source": [
    "# A comparison of CoMIGHT against KSG and Linear Regression Based Estimates of Conditional Independence\n",
    "\n",
    "CoMIGHT is a fully non-parametric method for i) estimating CMI and ii) providing a pvalue indicating the statistical significance of the estimated CMI compared to the null hypothesis where the CMI is 0 (for a given dimensionality and sample size using permutation principles).\n",
    "\n",
    "Another nonparametric method for CMI is the kNN based KSG estimator, which also can be used along a permutation test to obtain a pvalue.\n",
    "\n",
    "Finally, a parametric method for CMI is the linear regression method, which computes partial correlation among variables under the assumption that the data arises from Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b9e273-6364-47b5-a634-de1cfc588616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "from sklearn.datasets import (\n",
    "    make_blobs,\n",
    "    make_classification,\n",
    "    make_sparse_spd_matrix,\n",
    "    make_spd_matrix,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sktree import HonestForestClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sktree.datasets.multiview import make_gaussian_mixture, make_joint_factor_model\n",
    "from sktree.stats import (\n",
    "    FeatureImportanceForestClassifier,\n",
    "    FeatureImportanceForestRegressor,\n",
    "    PermutationForestRegressor,\n",
    ")\n",
    "from sktree.tree import DecisionTreeClassifier, MultiViewDecisionTreeClassifier\n",
    "\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3391a3a6-f802-4671-b467-006e43abe9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dodiscover.ci import CMITest, FisherZCITest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e44c3e-8ff5-47ea-9844-8a539b4f944b",
   "metadata": {},
   "source": [
    "# Define Dataset Generators\n",
    "\n",
    "1. Confounder: Y <- X1 -> X2\n",
    "2. Collider: X1 -> Y <- X2\n",
    "3. Independence: X1 -> Y  X2 (here we use `make_classification` from sklearn and add random noise)\n",
    "4. Mediator: X1 -> X2 -> Y\n",
    "5. Direct & Indirect Effects: X1 -> X2 -> Y; X1 -> Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f12b8bc-08c9-4147-bd07-883af4cacd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confounder(n_samples, n_features, noise_dims, class_probs, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    fixed_center = rng.standard_normal(size=(n_features,))\n",
    "    centers = [fixed_center, fixed_center]\n",
    "\n",
    "    covariances = [\n",
    "        make_spd_matrix(n_dim=n_features, random_state=seed),\n",
    "        make_spd_matrix(n_dim=n_features, random_state=seed + 123),\n",
    "    ]\n",
    "\n",
    "    Xs, y = make_gaussian_mixture(\n",
    "        centers,\n",
    "        covariances,\n",
    "        n_samples=n_samples,\n",
    "        noise=1.0,\n",
    "        noise_dims=noise_dims,\n",
    "        shuffle=True,\n",
    "        class_probs=class_probs,\n",
    "        random_state=seed + idx,\n",
    "    )\n",
    "\n",
    "    signal_X = np.hstack((Xs[1], Xs[0]))\n",
    "    n_features_ends = [\n",
    "        n_features + noise_dims,\n",
    "        n_features_2 + n_features + noise_dims * 2,\n",
    "    ]\n",
    "\n",
    "    return signal_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1020f77f-fc60-42e5-9df7-fc5b153031b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_collider(n_samples, n_features, noise_dims, seed):\n",
    "    signal_X_1, y1 = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features + noise_dims,\n",
    "        n_informative=n_features,\n",
    "        n_redundant=10,\n",
    "        n_repeated=0,\n",
    "        n_classes=2,\n",
    "        class_sep=1.0,\n",
    "        flip_y=0.02,\n",
    "        shuffle=False,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    signal_X_2, y2 = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features + noise_dims,\n",
    "        n_informative=n_features,\n",
    "        n_redundant=10,\n",
    "        n_repeated=0,\n",
    "        n_classes=2,\n",
    "        class_sep=0.75,\n",
    "        flip_y=0.02,\n",
    "        shuffle=False,\n",
    "        random_state=seed + 1,\n",
    "    )\n",
    "    signal_X = np.hstack((signal_X_1, signal_X_2))\n",
    "    y = y1.copy()\n",
    "\n",
    "    keep_inds = np.argwhere(y1 == y2)\n",
    "    y = y[keep_inds, ...]\n",
    "    y2 = y2[keep_inds, ...].squeeze()\n",
    "    signal_X = signal_X[keep_inds, ...].squeeze()\n",
    "\n",
    "    np.testing.assert_array_equal(y.squeeze(), y2)\n",
    "    return signal_X, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0a74cd-4d91-4aad-80e3-edd6b7f78c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mediator(n_samples, n_features, noise_dims, n_views, joint_rank, seed):\n",
    "    Xs, U, _ = make_joint_factor_model(\n",
    "        n_views,\n",
    "        n_features,\n",
    "        n_samples=n_samples,\n",
    "        joint_rank=joint_rank,\n",
    "        noise_std=10.0,\n",
    "        m=0.25,\n",
    "        random_state=seed,\n",
    "        return_decomp=True,\n",
    "    )\n",
    "\n",
    "    total_n_features = n_features * n_views + noise_dims\n",
    "\n",
    "    signal_X = np.hstack(Xs)\n",
    "    signal_X += rng.standard_normal(size=signal_X.shape)\n",
    "    signal_X = np.hstack(\n",
    "        (\n",
    "            signal_X,\n",
    "            rng.standard_normal(\n",
    "                size=(n_samples, total_n_features - n_features * n_views)\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    n_features_1 = signal_X.shape[1]\n",
    "\n",
    "    y = rng.binomial(n=1, p=expit(signal_X[:, :n_features].sum(axis=1)), size=n_samples)\n",
    "\n",
    "    # make signal view (i.e. X1) higher-dimensional\n",
    "    U += rng.standard_normal(size=U.shape)  # * 2.0\n",
    "    U = np.hstack(\n",
    "        (\n",
    "            U,\n",
    "            rng.standard_normal(\n",
    "                size=(signal_X.shape[0], total_n_features - joint_rank)\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # print(U.shape, signal_X.shape, y.shape, [x.shape for x in Xs])\n",
    "    # first view is X1, which generates X2\n",
    "    X = np.hstack((U, signal_X))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a354955-89e4-4529-908e-b23cc38a5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_direct_indirect_effects(n_samples, n_features, noise_dims, class_probs, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # make joint factor model for class 0\n",
    "    Xs_list = []\n",
    "    classes = []\n",
    "    for idx in range(2):\n",
    "        fixed_center = rng.standard_normal(size=(n_features,))\n",
    "        centers = [fixed_center, fixed_center]\n",
    "\n",
    "        covariances = [\n",
    "            make_spd_matrix(n_dim=n_features, random_state=seed + idx),\n",
    "            make_spd_matrix(n_dim=n_features, random_state=seed + 123 + idx),\n",
    "        ]\n",
    "\n",
    "        Xs, _ = make_gaussian_mixture(\n",
    "            centers,\n",
    "            covariances,\n",
    "            n_samples=math.ceil(n_samples // 2),\n",
    "            noise=1.0,\n",
    "            noise_dims=noise_dims,\n",
    "            shuffle=True,\n",
    "            class_probs=class_probs,\n",
    "            random_state=seed + idx,\n",
    "        )\n",
    "        signal_X = np.hstack((Xs[1], Xs[0]))\n",
    "        print(signal_X.shape)\n",
    "        Xs_list.append(signal_X)\n",
    "        classes.append(np.ones((n_samples // 2, 1)) * idx)\n",
    "\n",
    "    y = np.vstack(classes)\n",
    "    print([x.shape for x in Xs])\n",
    "    X = np.vstack(Xs_list)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06d7aa48-86ba-48f3-82c9-d5dd7fd96a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_mediator(500, 10, 80, 2, 5, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80de1fdb-4939-4a04-a9e3-b618530e8f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dec9ea25-de98-49b3-936a-38cd051d495b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 200)\n",
      "(250, 200)\n",
      "[(250, 100), (250, 100)]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_direct_indirect_effects(500, 10, 90, class_probs, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "544856f7-7c8b-4b7e-b82a-27b3a708e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098cefb-4f72-4411-b94b-3955e0b387e3",
   "metadata": {},
   "source": [
    "# Compare partial-AUC performance\n",
    "\n",
    "- compare against kNN\n",
    "- compare against linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e94b74-56ab-4130-963d-fb07647b601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = [0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0ee80-3239-48f6-ae70-e7aad90fd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 10\n",
    "noise_dims = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94eea5-0598-449d-bb39-c044cab36455",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 100\n",
    "n_estimators = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4159590-8f19-404d-87fe-eac60a9f781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0  800 1800 2800 3800 4800 5800 6800 7800 8800 9800]\n"
     ]
    }
   ],
   "source": [
    "n_features_2_list = np.linspace(800, 10_000 - 200, 10, dtype=int)\n",
    "n_features_2_list = np.insert(n_features_2_list, 0, 0)\n",
    "print(n_features_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2cc30-d7b9-4bc8-b364-a130bcae3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for idx in range(n_repeats):\n",
    "    n_features_begin = 0\n",
    "    X, y = make_confounder(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        noise_dims=noise_dims,\n",
    "        class_probs=class_probs,\n",
    "        seed=seed + idx,\n",
    "    )\n",
    "    n_features_ends = [\n",
    "        n_features + noise_dims,\n",
    "        n_features_2 + n_features + noise_dims * 2,\n",
    "    ]\n",
    "    # print(n_features_ends)\n",
    "\n",
    "    for n_features_2_ in n_features_2_list:\n",
    "        _X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2_))))\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        est = FeatureImportanceForestClassifier(\n",
    "            estimator=HonestForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "                    feature_set_ends=n_features_ends,\n",
    "                    apply_max_features_per_feature_set=True,\n",
    "                ),\n",
    "                random_state=seed,\n",
    "                honest_fraction=0.5,\n",
    "                n_jobs=n_jobs,\n",
    "            ),\n",
    "            random_state=seed,\n",
    "            test_size=test_size,\n",
    "            permute_per_tree=False,\n",
    "            sample_dataset_per_tree=False,\n",
    "        )\n",
    "\n",
    "        # compute the statistic\n",
    "        stat = est.statistic(X, y, metric=\"auc\", max_fpr=max_fpr)\n",
    "\n",
    "        results[\"mvrf\"].append(stat)\n",
    "        results[\"n_samples\"].append(n_samples)\n",
    "        results[\"n_features_2\"].append(n_features_2_)\n",
    "        results[\"noise_dims\"].append(noise_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50461758-da62-4737-a822-bb2479b12a9c",
   "metadata": {},
   "source": [
    "# Power plots (3rd Row): Compare now the PValues when Shuffling X2\n",
    "\n",
    "Here are the structures that are expected to reject the null because X1 \\not\\perp Y | X2:\n",
    "1. Confounder: Y <- X1 -> X2\n",
    "2. Collider: X1 -> Y <- X2\n",
    "3. Independence: X1 -> Y  X2 (here we use `make_classification` from sklearn and add random noise)\n",
    "4. Direct & Indirect Effects: X1 -> X2 -> Y; X1 -> Y\n",
    "\n",
    "Here are the structures that are expected to fail to reject the null:\n",
    "4. Mediator: X1 -> X2 -> Y\n",
    "5. Completely independent views: X1  Y  X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299be98e-2d81-4a2a-8750-5aa35b62a890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17932909-ba8f-476f-9f62-fee63a780ab8",
   "metadata": {},
   "source": [
    "# (4th Row): Compare now the PValues when Shuffling X1\n",
    "\n",
    "Now, we can reverse the question and compare what happens and if we correctly (fail-to) reject the null hypotheses.\n",
    "\n",
    "Here are the structures that are expected to reject the null because X1 \\not\\perp Y | X2:\n",
    "1. Confounder: Y <- X1 -> X2\n",
    "2. Collider: X1 -> Y <- X2\n",
    "3. Independence: X1 -> Y  X2 (here we use `make_classification` from sklearn and add random noise)\n",
    "4. Direct & Indirect Effects: X1 -> X2 -> Y; X1 -> Y\n",
    "\n",
    "Here are the structures that are expected to fail to reject the null:\n",
    "4. Mediator: X1 -> X2 -> Y\n",
    "5. Completely independent views: X1  Y  X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a498a-203e-4a92-ac48-663748f1ecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktree",
   "language": "python",
   "name": "sktree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
