{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4127d9dd-2851-409d-b709-420e24183431",
   "metadata": {},
   "source": [
    "# A comparison of CoMIGHT against KSG and Linear Regression Based Estimates of Conditional Independence\n",
    "\n",
    "CoMIGHT is a fully non-parametric method for i) estimating CMI and ii) providing a pvalue indicating the statistical significance of the estimated CMI compared to the null hypothesis where the CMI is 0 (for a given dimensionality and sample size using permutation principles).\n",
    "\n",
    "Another nonparametric method for CMI is the kNN based KSG estimator, which also can be used along a permutation test to obtain a pvalue.\n",
    "\n",
    "Finally, a parametric method for CMI is the linear regression method, which computes partial correlation among variables under the assumption that the data arises from Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60b9e273-6364-47b5-a634-de1cfc588616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "from sklearn.datasets import (\n",
    "    make_blobs,\n",
    "    make_classification,\n",
    "    make_sparse_spd_matrix,\n",
    "    make_spd_matrix,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sktree import HonestForestClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sktree.datasets.multiview import make_gaussian_mixture, make_joint_factor_model\n",
    "from sktree.stats import (\n",
    "    FeatureImportanceForestClassifier,\n",
    "    FeatureImportanceForestRegressor,\n",
    "    PermutationForestRegressor,\n",
    "    PermutationTest,\n",
    ")\n",
    "from sktree.tree import DecisionTreeClassifier, MultiViewDecisionTreeClassifier\n",
    "\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d4ad3eb-a5ec-4b32-af72-68e2005896ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e44c3e-8ff5-47ea-9844-8a539b4f944b",
   "metadata": {},
   "source": [
    "# Define Dataset Generators\n",
    "\n",
    "1. Confounder: Y <- X1 -> X2\n",
    "2. Collider: X1 -> Y <- X2\n",
    "3. Independence: X1 -> Y  X2 (here we use `make_classification` from sklearn and add random noise)\n",
    "4. Mediator: X1 -> X2 -> Y\n",
    "5. Direct & Indirect Effects: X1 -> X2 -> Y; X1 -> Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f12b8bc-08c9-4147-bd07-883af4cacd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confounder(n_samples, n_features, noise_dims, class_probs, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    fixed_center = rng.standard_normal(size=(n_features,))\n",
    "    centers = [fixed_center, fixed_center]\n",
    "\n",
    "    covariances = [\n",
    "        make_spd_matrix(n_dim=n_features, random_state=seed),\n",
    "        make_spd_matrix(n_dim=n_features, random_state=seed + 123),\n",
    "    ]\n",
    "\n",
    "    Xs, y = make_gaussian_mixture(\n",
    "        centers,\n",
    "        covariances,\n",
    "        n_samples=n_samples,\n",
    "        noise=1.0,\n",
    "        noise_dims=noise_dims,\n",
    "        shuffle=True,\n",
    "        class_probs=class_probs,\n",
    "        random_state=seed + idx,\n",
    "    )\n",
    "\n",
    "    signal_X = np.hstack((Xs[1], Xs[0]))\n",
    "\n",
    "    return signal_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1020f77f-fc60-42e5-9df7-fc5b153031b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_collider(n_samples, n_features, noise_dims, seed):\n",
    "    signal_X_1, y1 = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features + noise_dims,\n",
    "        n_informative=n_features,\n",
    "        n_redundant=10,\n",
    "        n_repeated=0,\n",
    "        n_classes=2,\n",
    "        class_sep=1.0,\n",
    "        flip_y=0.02,\n",
    "        shuffle=False,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    signal_X_2, y2 = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features + noise_dims,\n",
    "        n_informative=n_features,\n",
    "        n_redundant=10,\n",
    "        n_repeated=0,\n",
    "        n_classes=2,\n",
    "        class_sep=0.75,\n",
    "        flip_y=0.02,\n",
    "        shuffle=False,\n",
    "        random_state=seed + 1,\n",
    "    )\n",
    "    signal_X = np.hstack((signal_X_1, signal_X_2))\n",
    "    y = y1.copy()\n",
    "\n",
    "    keep_inds = np.argwhere(y1 == y2)\n",
    "    y = y[keep_inds, ...]\n",
    "    y2 = y2[keep_inds, ...].squeeze()\n",
    "    signal_X = signal_X[keep_inds, ...].squeeze()\n",
    "\n",
    "    np.testing.assert_array_equal(y.squeeze(), y2)\n",
    "    return signal_X, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0a74cd-4d91-4aad-80e3-edd6b7f78c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mediator(n_samples, n_features, noise_dims, n_views, joint_rank, seed):\n",
    "    Xs, U, _ = make_joint_factor_model(\n",
    "        n_views,\n",
    "        n_features,\n",
    "        n_samples=n_samples,\n",
    "        joint_rank=joint_rank,\n",
    "        noise_std=10.0,\n",
    "        m=0.25,\n",
    "        random_state=seed,\n",
    "        return_decomp=True,\n",
    "    )\n",
    "\n",
    "    total_n_features = n_features * n_views + noise_dims\n",
    "\n",
    "    signal_X = np.hstack(Xs)\n",
    "    signal_X += rng.standard_normal(size=signal_X.shape)\n",
    "    signal_X = np.hstack(\n",
    "        (\n",
    "            signal_X,\n",
    "            rng.standard_normal(\n",
    "                size=(n_samples, total_n_features - n_features * n_views)\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    n_features_1 = signal_X.shape[1]\n",
    "\n",
    "    y = rng.binomial(n=1, p=expit(signal_X[:, :n_features].sum(axis=1)), size=n_samples)\n",
    "\n",
    "    # make signal view (i.e. X1) higher-dimensional\n",
    "    U += rng.standard_normal(size=U.shape)  # * 2.0\n",
    "    U = np.hstack(\n",
    "        (\n",
    "            U,\n",
    "            rng.standard_normal(\n",
    "                size=(signal_X.shape[0], total_n_features - joint_rank)\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # print(U.shape, signal_X.shape, y.shape, [x.shape for x in Xs])\n",
    "    # first view is X1, which generates X2\n",
    "    X = np.hstack((U, signal_X))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a354955-89e4-4529-908e-b23cc38a5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_direct_indirect_effects(n_samples, n_features, noise_dims, class_probs, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # make joint factor model for class 0\n",
    "    Xs_list = []\n",
    "    classes = []\n",
    "    for idx in range(2):\n",
    "        fixed_center = rng.standard_normal(size=(n_features,))\n",
    "        centers = [fixed_center, fixed_center]\n",
    "\n",
    "        covariances = [\n",
    "            make_spd_matrix(n_dim=n_features, random_state=seed + idx),\n",
    "            make_spd_matrix(n_dim=n_features, random_state=seed + 123 + idx),\n",
    "        ]\n",
    "\n",
    "        Xs, _ = make_gaussian_mixture(\n",
    "            centers,\n",
    "            covariances,\n",
    "            n_samples=math.ceil(n_samples // 2),\n",
    "            noise=1.0,\n",
    "            noise_dims=noise_dims,\n",
    "            shuffle=True,\n",
    "            class_probs=class_probs,\n",
    "            random_state=seed + idx,\n",
    "        )\n",
    "        signal_X = np.hstack((Xs[1], Xs[0]))\n",
    "        print(signal_X.shape)\n",
    "        Xs_list.append(signal_X)\n",
    "        classes.append(np.ones((n_samples // 2, 1)) * idx)\n",
    "\n",
    "    y = np.vstack(classes)\n",
    "    print([x.shape for x in Xs])\n",
    "    X = np.vstack(Xs_list)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d7aa48-86ba-48f3-82c9-d5dd7fd96a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_mediator(500, 10, 80, 2, 5, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80de1fdb-4939-4a04-a9e3-b618530e8f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098cefb-4f72-4411-b94b-3955e0b387e3",
   "metadata": {},
   "source": [
    "# Compare partial-AUC performance\n",
    "\n",
    "- compare against kNN\n",
    "- compare against linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e94b74-56ab-4130-963d-fb07647b601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = [0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ca0ee80-3239-48f6-ae70-e7aad90fd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 10\n",
    "noise_dims = 90\n",
    "n_samples = 500\n",
    "max_features = 0.3\n",
    "n_jobs = -1\n",
    "test_size = 0.2\n",
    "\n",
    "max_fpr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b94eea5-0598-449d-bb39-c044cab36455",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 100\n",
    "n_estimators = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4159590-8f19-404d-87fe-eac60a9f781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0  800 1800 2800 3800 4800 5800 6800 7800 8800 9800]\n"
     ]
    }
   ],
   "source": [
    "n_features_2_list = np.linspace(800, 10_000 - 200, 10, dtype=int)\n",
    "n_features_2_list = np.insert(n_features_2_list, 0, 0)\n",
    "print(n_features_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2cc30-d7b9-4bc8-b364-a130bcae3a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500,)\n",
      "[100, 200]\n",
      "(500, 1000) (500,)\n",
      "[100, 1000]\n",
      "(500, 2000) (500,)\n",
      "[100, 2000]\n",
      "(500, 3000) (500,)\n",
      "[100, 3000]\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for idx in range(n_repeats):\n",
    "    n_features_begin = 0\n",
    "    signal_X, y = make_confounder(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        noise_dims=noise_dims,\n",
    "        class_probs=class_probs,\n",
    "        seed=seed + idx,\n",
    "    )\n",
    "    n_features_ends = [n_features + noise_dims, None]\n",
    "\n",
    "    for n_features_2_ in n_features_2_list:\n",
    "        _X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2_))))\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "        print(n_features_ends)\n",
    "\n",
    "        est = FeatureImportanceForestClassifier(\n",
    "            estimator=HonestForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "                    feature_set_ends=n_features_ends,\n",
    "                    apply_max_features_per_feature_set=True,\n",
    "                ),\n",
    "                random_state=seed,\n",
    "                honest_fraction=0.5,\n",
    "                n_jobs=n_jobs,\n",
    "            ),\n",
    "            random_state=seed,\n",
    "            test_size=test_size,\n",
    "            sample_dataset_per_tree=False,\n",
    "        )\n",
    "\n",
    "        # compute the statistic\n",
    "        # also compute the pvalue when shuffling X1\n",
    "        covariate_index = np.arange(0, n_features_ends[0])\n",
    "        stat, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x1\"].append(pvalue)\n",
    "        # get the actual partial-AUC of the unpermuted dataset for the forest\n",
    "        stat = est.observe_stat_\n",
    "        results[\"mvrf_pauc\"].append(stat)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=int(np.sqrt(X.shape[1])) + 1)\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "\n",
    "        results[\"knn_pauc\"].append(pauc)\n",
    "        results[\"knn_pvalue_x1\"].append(pauc)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        lr = LogisticRegression(random_state=seed + idx + n_features_2_)\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x1\"].append(pauc)\n",
    "        results[\"lr_pauc\"].append(pauc)\n",
    "\n",
    "        # now compute the pvalue when shuffling X2\n",
    "        covariate_index = np.arange(n_features_ends[0], n_features_ends[1])\n",
    "        _, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"knn_pvalue_x2\"].append(pauc)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x2\"].append(pauc)\n",
    "\n",
    "        results[\"n_samples\"].append(n_samples)\n",
    "        results[\"n_features_2\"].append(n_features_2_)\n",
    "        results[\"noise_dims\"].append(noise_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3831deb6-29d9-4036-b04d-f7d3913174b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
      "       ...\n",
      "       'x191', 'x192', 'x193', 'x194', 'x195', 'x196', 'x197', 'x198', 'x199',\n",
      "       'y0'],\n",
      "      dtype='object', length=201)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.concatenate((X, y[:, np.newaxis]), axis=1))\n",
    "x_cols = np.array([f\"x{idx}\" for idx in range(X.shape[1])])\n",
    "y_cols = np.array([f\"y0\"])\n",
    "z_cols = x_cols[0:2]\n",
    "df.columns = np.hstack((x_cols, y_cols))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "145490c4-e4da-442c-a589-a9f5428c54bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "<class 'dodiscover.ci.cmi_test.CMITest'> does not support multivariate input for X and Y.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m cmi_test \u001b[38;5;241m=\u001b[39m CMITest(\n\u001b[1;32m      2\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_seed\u001b[38;5;241m=\u001b[39mseed \u001b[38;5;241m+\u001b[39m idx \u001b[38;5;241m+\u001b[39m n_features_2_\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m _, pvalue \u001b[38;5;241m=\u001b[39m \u001b[43mcmi_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_cols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dodiscover/dodiscover/ci/cmi_test.py:108\u001b[0m, in \u001b[0;36mCMITest.test\u001b[0;34m(self, df, x_vars, y_vars, z_covariates)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m z_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     z_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_test_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_covariates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# preprocess and transform the data; called here only once\u001b[39;00m\n\u001b[1;32m    111\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(df)\n",
      "File \u001b[0;32m~/Documents/dodiscover/dodiscover/ci/base.py:45\u001b[0m, in \u001b[0;36mBaseConditionalIndependenceTest._check_test_input\u001b[0;34m(self, df, x_vars, y_vars, z_covariates)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe z conditioning set variables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz_covariates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not all in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_multivariate_input \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(x_vars) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_vars) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support multivariate input for X and Y.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: <class 'dodiscover.ci.cmi_test.CMITest'> does not support multivariate input for X and Y."
     ]
    }
   ],
   "source": [
    "cmi_test = CMITest(\n",
    "    k=0.2, n_jobs=-1, n_shuffle=1000, random_seed=seed + idx + n_features_2_\n",
    ")\n",
    "_, pvalue = cmi_test.test(df, x_cols, y_cols, z_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50461758-da62-4737-a822-bb2479b12a9c",
   "metadata": {},
   "source": [
    "# Power plots (3rd Row): Compare now the PValues when Shuffling X2\n",
    "\n",
    "Here are the structures that are expected to reject the null because X1 \\not\\perp Y | X2:\n",
    "1. Confounder: Y <- X1 -> X2\n",
    "2. Collider: X1 -> Y <- X2\n",
    "3. Independence: X1 -> Y  X2 (here we use `make_classification` from sklearn and add random noise)\n",
    "4. Direct & Indirect Effects: X1 -> X2 -> Y; X1 -> Y\n",
    "\n",
    "Here are the structures that are expected to fail to reject the null:\n",
    "4. Mediator: X1 -> X2 -> Y\n",
    "5. Completely independent views: X1  Y  X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299be98e-2d81-4a2a-8750-5aa35b62a890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17932909-ba8f-476f-9f62-fee63a780ab8",
   "metadata": {},
   "source": [
    "# (4th Row): Compare now the PValues when Shuffling X1\n",
    "\n",
    "Now, we can reverse the question and compare what happens and if we correctly (fail-to) reject the null hypotheses.\n",
    "\n",
    "Here are the structures that are expected to reject the null because X1 \\not\\perp Y | X2:\n",
    "1. Confounder: Y <- X1 -> X2\n",
    "2. Collider: X1 -> Y <- X2\n",
    "3. Independence: X1 -> Y  X2 (here we use `make_classification` from sklearn and add random noise)\n",
    "4. Direct & Indirect Effects: X1 -> X2 -> Y; X1 -> Y\n",
    "\n",
    "Here are the structures that are expected to fail to reject the null:\n",
    "4. Mediator: X1 -> X2 -> Y\n",
    "5. Completely independent views: X1  Y  X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a498a-203e-4a92-ac48-663748f1ecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktree",
   "language": "python",
   "name": "sktree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
