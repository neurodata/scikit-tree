{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0779510-d8cc-4d41-9408-b9258fbd66f3",
   "metadata": {},
   "source": [
    "# Old Scripts for Running different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "64268ea3-5ed3-41ec-a2cf-e002bb249647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mediator(\n",
    "    n_samples, n_features, noise_dims, n_features_1, n_views, joint_rank, seed\n",
    "):\n",
    "    Xs, U, _ = make_joint_factor_model(\n",
    "        n_views,\n",
    "        n_features,\n",
    "        n_samples=n_samples,\n",
    "        joint_rank=joint_rank,\n",
    "        noise_std=10.0,\n",
    "        m=0.5,\n",
    "        random_state=seed,\n",
    "        return_decomp=True,\n",
    "    )\n",
    "    # total_n_features = n_features * n_views + noise_dims\n",
    "\n",
    "    signal_X = np.hstack(Xs)\n",
    "    signal_X += rng.standard_normal(size=signal_X.shape) * 2.0\n",
    "    print(signal_X.shape)\n",
    "    y = rng.binomial(n=1, p=expit(signal_X[:, :n_features].sum(axis=1)), size=n_samples)\n",
    "\n",
    "    # make signal view (i.e. X1) higher-dimensional\n",
    "    U += rng.standard_normal(size=U.shape)\n",
    "    U = np.hstack(\n",
    "        (\n",
    "            U,\n",
    "            rng.standard_normal(size=(signal_X.shape[0], n_features_1 - U.shape[1])),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # first view is X1, which generates X2\n",
    "    X = np.hstack((U, signal_X))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c486f-8602-4350-a974-c1beb4300845",
   "metadata": {},
   "source": [
    "## Mediator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "3f7907c0-d97c-460b-80f2-6db8efa74e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mediator_dataset(\n",
    "    n_samples, n_features, class_probs, test_size, max_fpr, n_repeats, seed\n",
    "):\n",
    "    n_views = 2\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for idx in range(n_repeats):\n",
    "        n_features_begin = 0\n",
    "        signal_X, y = make_mediator(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features // 2,\n",
    "            noise_dims=noise_dims // 2,\n",
    "            n_features_1=100,\n",
    "            n_views=n_views,\n",
    "            joint_rank=5,\n",
    "            seed=seed * idx,\n",
    "        )\n",
    "        n_features_ends = [100, None]\n",
    "\n",
    "        _X = np.hstack(\n",
    "            (\n",
    "                signal_X,\n",
    "                rng.standard_normal(\n",
    "                    size=(n_samples, n_features_2_list[-1] - n_features)\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        print(X.shape, signal_X.shape, y.shape, n_features_ends)\n",
    "        np.savez(f\"./mediator/mediator_{idx}.npz\", X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "5f0ccc04-a2ca-4510-9b60-ded769c85b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n",
      "(256, 10)\n",
      "(256, 4196) (256, 110) (256,) [100, 4196]\n"
     ]
    }
   ],
   "source": [
    "generate_mediator_dataset(\n",
    "    n_samples, n_features, class_probs, test_size, max_fpr, n_repeats, seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855124c-62c9-4494-bd40-d930d481ca69",
   "metadata": {},
   "source": [
    "## Collider Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e4cb9-92ae-424d-a76c-f02faf8abc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "_results_collider = Parallel(n_jobs=-1)(\n",
    "    delayed(_run_parallel_sim)(\n",
    "        idx_,\n",
    "        n_samples,\n",
    "        n_features,\n",
    "        class_probs,\n",
    "        seed,\n",
    "        n_features_2_,\n",
    "        test_size,\n",
    "        max_fpr,\n",
    "        \"collider\",\n",
    "    )\n",
    "    for (idx_, n_features_2_) in product(range(n_repeats), n_features_2_list[1:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea72d779-0023-4df4-8fc4-9879f3199cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500,)\n",
      "[100, 200]\n",
      "(500, 1000) (500,)\n",
      "[100, 1000]\n",
      "(500, 2000) (500,)\n",
      "[100, 2000]\n",
      "(500, 3000) (500,)\n",
      "[100, 3000]\n",
      "(500, 4000) (500,)\n",
      "[100, 4000]\n",
      "(500, 5000) (500,)\n",
      "[100, 5000]\n",
      "(500, 6000) (500,)\n",
      "[100, 6000]\n",
      "(500, 7000) (500,)\n",
      "[100, 7000]\n",
      "(500, 8000) (500,)\n",
      "[100, 8000]\n",
      "(500, 9000) (500,)\n",
      "[100, 9000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# compute the statistic\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# also compute the pvalue when shuffling X1\u001b[39;00m\n\u001b[1;32m     40\u001b[0m covariate_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, n_features_ends[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 41\u001b[0m stat, pvalue \u001b[38;5;241m=\u001b[39m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmvrf_pvalue_x1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pvalue)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# get the actual partial-AUC of the unpermuted dataset for the forest\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/scikit-tree/sktree/stats/forestht.py:544\u001b[0m, in \u001b[0;36mBaseForestHT.test\u001b[0;34m(self, X, y, covariate_index, metric, n_repeats, return_posteriors, **metric_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m     covariate_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# next permute the data\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m permute_stat, permute_posteriors, permute_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatistic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_posteriors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_posteriors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_stat_ \u001b[38;5;241m=\u001b[39m permute_stat\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# Note: at this point, both `estimator` and `permuted_estimator_` should\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# have been fitted already, so we can now compute on the null by resampling\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# the posteriors and computing the test statistic on the resampled posteriors\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/scikit-tree/sktree/stats/forestht.py:464\u001b[0m, in \u001b[0;36mBaseForestHT.statistic\u001b[0;34m(self, X, y, covariate_index, metric, return_posteriors, check_input, **metric_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC metric is not supported for multi-output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statistic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_posteriors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_posteriors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/scikit-tree/sktree/stats/forestht.py:1112\u001b[0m, in \u001b[0;36mFeatureImportanceForestClassifier._statistic\u001b[0;34m(self, estimator, X, y, covariate_index, metric, return_posteriors, **metric_kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_of_target_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1111\u001b[0m         y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m-> 1112\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# list of tree outputs. Each tree output is (n_samples, n_outputs), or (n_samples,)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predict_posteriors:\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;66;03m# all_proba = Parallel(n_jobs=estimator.n_jobs, verbose=self.verbose)(\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m#     delayed(_parallel_predict_proba)(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# TODO: probably a more elegant way of doing this\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/scikit-tree/sktree/ensemble/_honest_forest.py:412\u001b[0m, in \u001b[0;36mHonestForestClassifier.fit\u001b[0;34m(self, X, y, sample_weight, classes)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03mBuild a forest of trees from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m    Fitted tree estimator.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Compute honest decision function\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhonest_decision_function_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba(\n\u001b[1;32m    416\u001b[0m     X, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhonest_indices_, impute_missing\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m    417\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/scikit-tree/sktree/_lib/./sklearn/ensemble/_forest.py:596\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight, classes)\u001b[0m\n\u001b[1;32m    585\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    588\u001b[0m ]\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/joblib/parallel.py:1713\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n\u001b[0;32m-> 1713\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   1714\u001b[0m     batched_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;66;03m# Flatten the batched results to output one output at a time\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for idx in range(n_repeats):\n",
    "    n_features_begin = 0\n",
    "    signal_X, y = make_collider(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        noise_dims=noise_dims,\n",
    "        seed=seed + idx,\n",
    "    )\n",
    "    n_features_ends = [n_features + noise_dims, None]\n",
    "\n",
    "    for n_features_2_ in n_features_2_list:\n",
    "        _X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2_))))\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "        print(n_features_ends)\n",
    "\n",
    "        est = FeatureImportanceForestClassifier(\n",
    "            estimator=HonestForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "                    feature_set_ends=n_features_ends,\n",
    "                    apply_max_features_per_feature_set=True,\n",
    "                ),\n",
    "                random_state=seed,\n",
    "                honest_fraction=0.5,\n",
    "                n_jobs=n_jobs,\n",
    "            ),\n",
    "            random_state=seed,\n",
    "            test_size=test_size,\n",
    "            sample_dataset_per_tree=False,\n",
    "        )\n",
    "\n",
    "        # compute the statistic\n",
    "        # also compute the pvalue when shuffling X1\n",
    "        covariate_index = np.arange(0, n_features_ends[0])\n",
    "        stat, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x1\"].append(pvalue)\n",
    "        # get the actual partial-AUC of the unpermuted dataset for the forest\n",
    "        stat = est.observe_stat_\n",
    "        results[\"mvrf_pauc\"].append(stat)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=int(np.sqrt(X.shape[1])) + 1)\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "\n",
    "        results[\"knn_pauc\"].append(pauc)\n",
    "        results[\"knn_pvalue_x1\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        lr = LogisticRegression(random_state=seed + idx + n_features_2_)\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x1\"].append(pvalue)\n",
    "        results[\"lr_pauc\"].append(pauc)\n",
    "\n",
    "        # now compute the pvalue when shuffling X2\n",
    "        covariate_index = np.arange(n_features_ends[0], n_features_ends[1])\n",
    "        _, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"knn_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        results[\"n_samples\"].append(n_samples)\n",
    "        results[\"n_features_2\"].append(n_features_2_)\n",
    "        results[\"noise_dims\"].append(noise_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38588e15-02cb-488f-ac57-1e09561e89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# save the results\n",
    "df.to_csv(\"./cv_comight_mv_vs_knn_vs_lr_collider_model.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37609a82-24a8-4fd4-87fc-9d2083ddf572",
   "metadata": {},
   "source": [
    "## Mediator Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a7fa9c-d1e0-4f7e-8aaf-4b152ead673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5\n",
    "noise_dims = 90\n",
    "n_views = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2279b76f-352e-4e0b-9d9f-11c8757be32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500,)\n",
      "[100, 200]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# compute the statistic\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# also compute the pvalue when shuffling X1\u001b[39;00m\n\u001b[1;32m     42\u001b[0m covariate_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, n_features_ends[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 43\u001b[0m stat, pvalue \u001b[38;5;241m=\u001b[39m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmvrf_pvalue_x1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pvalue)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# get the actual partial-AUC of the unpermuted dataset for the forest\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/forestht.py:526\u001b[0m, in \u001b[0;36mBaseForestHT.test\u001b[0;34m(self, X, y, covariate_index, metric, n_repeats, return_posteriors, **metric_kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m X, y, covariate_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, y, covariate_index)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_fitted:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;66;03m# first compute the test statistic on the un-permuted data\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     observe_stat, observe_posteriors, observe_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatistic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_posteriors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_posteriors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    536\u001b[0m     observe_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserve_samples_\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/forestht.py:464\u001b[0m, in \u001b[0;36mBaseForestHT.statistic\u001b[0;34m(self, X, y, covariate_index, metric, return_posteriors, check_input, **metric_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC metric is not supported for multi-output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statistic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_posteriors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_posteriors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/forestht.py:1112\u001b[0m, in \u001b[0;36mFeatureImportanceForestClassifier._statistic\u001b[0;34m(self, estimator, X, y, covariate_index, metric, return_posteriors, **metric_kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_of_target_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1111\u001b[0m         y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m-> 1112\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# list of tree outputs. Each tree output is (n_samples, n_outputs), or (n_samples,)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predict_posteriors:\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;66;03m# all_proba = Parallel(n_jobs=estimator.n_jobs, verbose=self.verbose)(\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m#     delayed(_parallel_predict_proba)(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# TODO: probably a more elegant way of doing this\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/ensemble/_honest_forest.py:412\u001b[0m, in \u001b[0;36mHonestForestClassifier.fit\u001b[0;34m(self, X, y, sample_weight, classes)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03mBuild a forest of trees from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m    Fitted tree estimator.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Compute honest decision function\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhonest_decision_function_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba(\n\u001b[1;32m    416\u001b[0m     X, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhonest_indices_, impute_missing\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m    417\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/_lib/sklearn/ensemble/_forest.py:596\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight, classes)\u001b[0m\n\u001b[1;32m    585\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    588\u001b[0m ]\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for idx in range(n_repeats):\n",
    "    n_features_begin = 0\n",
    "    signal_X, y = make_mediator(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        noise_dims=noise_dims,\n",
    "        n_views=n_views,\n",
    "        joint_rank=5,\n",
    "        seed=seed + idx,\n",
    "    )\n",
    "    n_features_ends = [n_views * n_features + noise_dims, None]\n",
    "\n",
    "    for n_features_2_ in n_features_2_list:\n",
    "        _X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2_))))\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "        print(n_features_ends)\n",
    "\n",
    "        est = FeatureImportanceForestClassifier(\n",
    "            estimator=HonestForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "                    feature_set_ends=n_features_ends,\n",
    "                    apply_max_features_per_feature_set=True,\n",
    "                ),\n",
    "                random_state=seed,\n",
    "                honest_fraction=0.5,\n",
    "                n_jobs=n_jobs,\n",
    "            ),\n",
    "            random_state=seed,\n",
    "            test_size=test_size,\n",
    "            sample_dataset_per_tree=False,\n",
    "        )\n",
    "\n",
    "        # compute the statistic\n",
    "        # also compute the pvalue when shuffling X1\n",
    "        covariate_index = np.arange(0, n_features_ends[0])\n",
    "        stat, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x1\"].append(pvalue)\n",
    "        # get the actual partial-AUC of the unpermuted dataset for the forest\n",
    "        stat = est.observe_stat_\n",
    "        results[\"mvrf_pauc\"].append(stat)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=int(np.sqrt(X.shape[1])) + 1)\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "\n",
    "        results[\"knn_pauc\"].append(pauc)\n",
    "        results[\"knn_pvalue_x1\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        lr = LogisticRegression(random_state=seed + idx + n_features_2_)\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x1\"].append(pvalue)\n",
    "        results[\"lr_pauc\"].append(pauc)\n",
    "\n",
    "        # now compute the pvalue when shuffling X2\n",
    "        covariate_index = np.arange(n_features_ends[0], n_features_ends[1])\n",
    "        _, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"knn_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        results[\"n_samples\"].append(n_samples)\n",
    "        results[\"n_features_2\"].append(n_features_2_)\n",
    "        results[\"noise_dims\"].append(noise_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfd708-b4ea-4a0e-9fcc-31831c94ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# save the results\n",
    "df.to_csv(\"./cv_comight_mv_vs_knn_vs_lr_mediator_model.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979260fd-708a-4f52-a95a-83dee0861461",
   "metadata": {},
   "source": [
    "## Direct/Indirect Effect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88e5f73a-62bf-43d1-a385-dc44e5df8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 10\n",
    "noise_dims = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b68da23e-daaa-49ed-a555-d8ac349b455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 200)\n",
      "(250, 200)\n",
      "[(250, 100), (250, 100)]\n",
      "(500, 200) (500, 1)\n",
      "[100, 200]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# compute pvalue for kNN based job\u001b[39;00m\n\u001b[1;32m     53\u001b[0m permest \u001b[38;5;241m=\u001b[39m PermutationTest(\n\u001b[1;32m     54\u001b[0m     neigh, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed \u001b[38;5;241m+\u001b[39m idx \u001b[38;5;241m+\u001b[39m n_features_2_\n\u001b[1;32m     55\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m pauc, pvalue \u001b[38;5;241m=\u001b[39m \u001b[43mpermest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn_pauc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pauc)\n\u001b[1;32m     61\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn_pvalue_x1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pvalue)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/monte_carlo.py:116\u001b[0m, in \u001b[0;36mPermutationTest.test\u001b[0;34m(self, X, y, covariate_index, metric, n_repeats, return_posteriors, **metric_kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserve_stat_ \u001b[38;5;241m=\u001b[39m pauc\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# compute null distribution of the test statistic\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# WARNING: this could take a long time, since it fits a new forest\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m null_dist \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_null_distribution_perm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_posteriors:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnull_dist_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(null_dist)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/utils.py:162\u001b[0m, in \u001b[0;36m_compute_null_distribution_perm\u001b[0;34m(X_train, y_train, X_test, y_test, covariate_index, est, metric, n_repeats, seed, **metric_kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# train a new forest on the permuted data\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# XXX: should there be a train/test split here? even w/ honest forests?\u001b[39;00m\n\u001b[1;32m    161\u001b[0m est\u001b[38;5;241m.\u001b[39mfit(X_train, y_train\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m--> 162\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# compute two instances of the metric from the sampled trees\u001b[39;00m\n\u001b[1;32m    165\u001b[0m metric_val \u001b[38;5;241m=\u001b[39m metric_func(y_test, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetric_kwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:254\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    252\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[1;32m    253\u001b[0m     ):\n\u001b[0;32m--> 254\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    257\u001b[0m                 [\n\u001b[1;32m    258\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[idx][np\u001b[38;5;241m.\u001b[39margmax(probas, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    262\u001b[0m             )\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:355\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/neighbors/_base.py:822\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    815\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    818\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    819\u001b[0m     )\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 822\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    834\u001b[0m ):\n\u001b[1;32m    835\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    836\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    837\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:259\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    272\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    273\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:90\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/threadpoolctl.py:440\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for idx in range(n_repeats):\n",
    "    n_features_begin = 0\n",
    "    signal_X, y = make_direct_indirect_effects(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        noise_dims=noise_dims,\n",
    "        class_probs=class_probs,\n",
    "        seed=seed + idx,\n",
    "    )\n",
    "    n_features_ends = [n_features + noise_dims, None]\n",
    "\n",
    "    for n_features_2_ in n_features_2_list:\n",
    "        _X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2_))))\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "        print(n_features_ends)\n",
    "\n",
    "        est = FeatureImportanceForestClassifier(\n",
    "            estimator=HonestForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "                    feature_set_ends=n_features_ends,\n",
    "                    apply_max_features_per_feature_set=True,\n",
    "                ),\n",
    "                random_state=seed,\n",
    "                honest_fraction=0.5,\n",
    "                n_jobs=n_jobs,\n",
    "            ),\n",
    "            random_state=seed,\n",
    "            test_size=test_size,\n",
    "            sample_dataset_per_tree=False,\n",
    "        )\n",
    "\n",
    "        # compute the statistic\n",
    "        # also compute the pvalue when shuffling X1\n",
    "        covariate_index = np.arange(0, n_features_ends[0])\n",
    "        stat, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x1\"].append(pvalue)\n",
    "        # get the actual partial-AUC of the unpermuted dataset for the forest\n",
    "        stat = est.observe_stat_\n",
    "        results[\"mvrf_pauc\"].append(stat)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=int(np.sqrt(X.shape[1])) + 1)\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "\n",
    "        results[\"knn_pauc\"].append(pauc)\n",
    "        results[\"knn_pvalue_x1\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        lr = LogisticRegression(random_state=seed + idx + n_features_2_)\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x1\"].append(pvalue)\n",
    "        results[\"lr_pauc\"].append(pauc)\n",
    "\n",
    "        # now compute the pvalue when shuffling X2\n",
    "        covariate_index = np.arange(n_features_ends[0], n_features_ends[1])\n",
    "        _, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"knn_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        results[\"n_samples\"].append(n_samples)\n",
    "        results[\"n_features_2\"].append(n_features_2_)\n",
    "        results[\"noise_dims\"].append(noise_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532eb37-b7f9-4dca-b2c4-06e167ad4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# save the results\n",
    "df.to_csv(\"./cv_comight_mv_vs_knn_vs_lr_directindirecteffects_model.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f4915-c8c4-440c-a70f-8813cdd23c92",
   "metadata": {},
   "source": [
    "## Independent View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "859305b5-3b2d-4e47-a27b-b057cb1b122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100  900 1900 2900 3900 4900 5900 6900 7900 8900 9900]\n"
     ]
    }
   ],
   "source": [
    "n_features = 20\n",
    "noise_dims = 80\n",
    "n_samples = 500\n",
    "max_features = 0.3\n",
    "n_jobs = -1\n",
    "test_size = 0.2\n",
    "\n",
    "max_fpr = 0.1\n",
    "\n",
    "n_features_2_list = np.linspace(900, 10_000 - 100, 10, dtype=int)\n",
    "n_features_2_list = np.insert(n_features_2_list, 0, 100)\n",
    "print(n_features_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32126481-52f3-41b6-b539-7a352aa8d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200) (500,)\n",
      "[100, 200]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# compute pvalue for kNN based job\u001b[39;00m\n\u001b[1;32m     52\u001b[0m permest \u001b[38;5;241m=\u001b[39m PermutationTest(\n\u001b[1;32m     53\u001b[0m     neigh, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed \u001b[38;5;241m+\u001b[39m idx \u001b[38;5;241m+\u001b[39m n_features_2_\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0m pauc, pvalue \u001b[38;5;241m=\u001b[39m \u001b[43mpermest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn_pauc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pauc)\n\u001b[1;32m     60\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn_pvalue_x1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pvalue)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/monte_carlo.py:116\u001b[0m, in \u001b[0;36mPermutationTest.test\u001b[0;34m(self, X, y, covariate_index, metric, n_repeats, return_posteriors, **metric_kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserve_stat_ \u001b[38;5;241m=\u001b[39m pauc\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# compute null distribution of the test statistic\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# WARNING: this could take a long time, since it fits a new forest\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m null_dist \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_null_distribution_perm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovariate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_posteriors:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnull_dist_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(null_dist)\n",
      "File \u001b[0;32m~/miniforge3/envs/sktree/lib/python3.9/site-packages/sktree/stats/utils.py:155\u001b[0m, in \u001b[0;36m_compute_null_distribution_perm\u001b[0;34m(X_train, y_train, X_test, y_test, covariate_index, est, metric, n_repeats, seed, **metric_kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m perm_X_cov \u001b[38;5;241m=\u001b[39m X_test[test_index_arr, covariate_index]\n\u001b[1;32m    153\u001b[0m X_test[:, covariate_index] \u001b[38;5;241m=\u001b[39m perm_X_cov\n\u001b[0;32m--> 155\u001b[0m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m perm_X_cov \u001b[38;5;241m=\u001b[39m X_train[train_index_arr, covariate_index]\n\u001b[1;32m    157\u001b[0m X_train[:, covariate_index] \u001b[38;5;241m=\u001b[39m perm_X_cov\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for idx in range(n_repeats):\n",
    "    n_features_begin = 0\n",
    "    signal_X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features + noise_dims,\n",
    "        n_informative=n_features,\n",
    "        random_state=seed + idx,\n",
    "    )\n",
    "    n_features_ends = [n_features + noise_dims, None]\n",
    "\n",
    "    for n_features_2_ in n_features_2_list:\n",
    "        _X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2_))))\n",
    "        X = _X.copy()\n",
    "        n_features_ends[1] = X.shape[1]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "        print(n_features_ends)\n",
    "\n",
    "        est = FeatureImportanceForestClassifier(\n",
    "            estimator=HonestForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                tree_estimator=MultiViewDecisionTreeClassifier(\n",
    "                    feature_set_ends=n_features_ends,\n",
    "                    apply_max_features_per_feature_set=True,\n",
    "                ),\n",
    "                random_state=seed,\n",
    "                honest_fraction=0.5,\n",
    "                n_jobs=n_jobs,\n",
    "            ),\n",
    "            random_state=seed,\n",
    "            test_size=test_size,\n",
    "            sample_dataset_per_tree=False,\n",
    "        )\n",
    "\n",
    "        # compute the statistic\n",
    "        # also compute the pvalue when shuffling X1\n",
    "        covariate_index = np.arange(0, n_features_ends[0])\n",
    "        stat, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x1\"].append(pvalue)\n",
    "        # get the actual partial-AUC of the unpermuted dataset for the forest\n",
    "        stat = est.observe_stat_\n",
    "        results[\"mvrf_pauc\"].append(stat)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        neigh = KNeighborsClassifier(n_neighbors=int(np.sqrt(X.shape[1])) + 1)\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "\n",
    "        results[\"knn_pauc\"].append(pauc)\n",
    "        results[\"knn_pvalue_x1\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        lr = LogisticRegression(random_state=seed + idx + n_features_2_)\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        pauc, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x1\"].append(pvalue)\n",
    "        results[\"lr_pauc\"].append(pauc)\n",
    "\n",
    "        # now compute the pvalue when shuffling X2\n",
    "        covariate_index = np.arange(n_features_ends[0], n_features_ends[1])\n",
    "        _, pvalue = est.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"mvrf_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # now compute the same relevant quantities using kNN\n",
    "        # compute pvalue for kNN based job\n",
    "        permest = PermutationTest(\n",
    "            neigh, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"knn_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        # also compute the relevant quantities using linear regression\n",
    "        permest = PermutationTest(\n",
    "            lr, n_repeats=100, random_state=seed + idx + n_features_2_\n",
    "        )\n",
    "        _, pvalue = permest.test(\n",
    "            X, y, covariate_index=covariate_index, metric=\"auc\", max_fpr=max_fpr\n",
    "        )\n",
    "        results[\"lr_pvalue_x2\"].append(pvalue)\n",
    "\n",
    "        results[\"n_samples\"].append(n_samples)\n",
    "        results[\"n_features_2\"].append(n_features_2_)\n",
    "        results[\"noise_dims\"].append(noise_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54b9dd-494d-4028-b295-8502ebecb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# save the results\n",
    "df.to_csv(\"./cv_comight_mv_vs_knn_vs_lr_independentview_model.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf341dd3-6e3f-4635-a75a-19152cd98488",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cv_comight_mv_vs_knn_vs_lr_confounder_model.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"./cv_comight_mv_vs_knn_vs_lr_confounder_model.csv\", index_col=0, header=0\n",
    ")\n",
    "\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktree",
   "language": "python",
   "name": "sktree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
