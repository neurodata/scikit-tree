{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Co-MIGHT when Data Exhibits Conditional Independence\n\nIn this example, we demonstrate how to test the conditional mutual information (CMI)\nhypothesis test using conditional mutual information for genuine hypothesis test (Co-MIGHT).\nTo perform CMI testing, we have the hypothesis test:\n\n- $H_0: I(X_2; Y | X_1) = 0$\n- $H_1: I(X_2; Y | X_1) > 0$\n\nHere, we simulate two feature-sets, which follow the null-hypothesis with the specific\nsetting that $X_2 \\perp \\{Y, X_1\\}$. We will test using the multi-view decision\ntree to verify that that the null hypothesis is not rejected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import make_classification\n\nfrom sktree import HonestForestClassifier\nfrom sktree.stats import FeatureImportanceForestClassifier\nfrom sktree.tree import DecisionTreeClassifier, MultiViewDecisionTreeClassifier\n\nseed = 12345\nrng = np.random.default_rng(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate data\nWe simulate the two feature sets, and the target variable. We then combine them\ninto a single dataset to perform hypothesis testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 200\nn_features_1 = 20\nnoise_dims = 80\nn_features_2 = 1000\n\nsignal_X, y = make_classification(\n    n_samples=n_samples,\n    n_features=n_features_1 + noise_dims,\n    n_informative=n_features_1,\n    n_redundant=50,\n    n_repeated=0,\n    n_classes=2,\n    class_sep=0.5,\n    flip_y=0.01,\n    shuffle=True,\n    random_state=seed,\n)\n\n# model parameters\nn_estimators = 200\nmax_features = 0.3\ntest_size = 0.2\nn_repeats = 1000\nn_jobs = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis when the null hypothesis is true\nLet's now investigate what happens when the null hypothesis is true. We will simulate\ndata from the graphical model:\n\n$(X_1 \\\\rightarrow Y; X_2)$\n\nHere, we either have $X_1$ or $X_2$ informative for the target, but not both. We will\nthen perform hypothesis testing using the same procedure as above. We will test the settings\nwhen the high-dimensional feature-set is informative for the target, and when the\nlow-dimensional feature-set is informative for the target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Make X_2 high-dimensional\nn_features_ends = [n_features_1 + noise_dims, signal_X.shape[1]]\n_X = np.hstack((signal_X, rng.standard_normal(size=(n_samples, n_features_2))))\nX = _X.copy()\nn_features_ends[1] = X.shape[1]\n\nprint(X.shape, y.shape, n_features_ends)\n\nest = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=MultiViewDecisionTreeClassifier(\n            feature_set_ends=n_features_ends,\n            apply_max_features_per_feature_set=True,\n        ),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n    sample_dataset_per_tree=False,\n)\n\nrf_est = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=DecisionTreeClassifier(),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n)\n\nrf_results = dict()\nmv_results = dict()\n\n# we test for the first feature set, which is lower-dimensional\ncovariate_index = np.arange(n_features_ends[0], dtype=int)\nstat, pvalue = est.test(X, y, covariate_index=covariate_index, metric=\"mi\", n_repeats=n_repeats)\n\nmv_results[\"low_dim_feature_stat\"] = stat\nmv_results[\"low_dim_feature_pvalue\"] = pvalue\nprint(\"\\n\\nImportant feature-set is low-dimensional\")\nprint(f\"Estimated MI difference with first view (has dependency): {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is higher-dimensional\ncovariate_index = np.arange(n_features_ends[0], n_features_ends[1], dtype=int)\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=covariate_index,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nmv_results[\"high_dim_feature_stat\"] = stat\nmv_results[\"high_dim_feature_pvalue\"] = pvalue\nprint(\n    f\"Estimated MI difference testing second view (does not have dependency): \"\n    f\"{stat} with Pvalue: {pvalue}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will compare with using a standard decision tree classifier as our base model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covariate_index = np.arange(n_features_ends[0], dtype=int)\nstat, pvalue = rf_est.test(X, y, covariate_index=covariate_index, metric=\"mi\", n_repeats=n_repeats)\n\nrf_results[\"low_dim_feature_stat\"] = stat\nrf_results[\"low_dim_feature_pvalue\"] = pvalue\nprint(\"\\n\\nComparing with random forest.\")\nprint(f\"Estimated MI difference with first view (has dependency): {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is higher-dimensional\ncovariate_index = np.arange(n_features_ends[0], n_features_ends[1], dtype=int)\nstat, pvalue = rf_est.test(\n    X,\n    y,\n    covariate_index=covariate_index,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nrf_results[\"high_dim_feature_stat\"] = stat\nrf_results[\"high_dim_feature_pvalue\"] = pvalue\nprint(\n    f\"Estimated MI difference testing second view (does not have dependency): \"\n    f\"{stat} with Pvalue: {pvalue}\"\n)\n\nfig, ax = plt.subplots(figsize=(5, 3))\n\n# plot pvalues\nax.bar(0, rf_results[\"low_dim_feature_pvalue\"], label=\"Low-dim Feature Set (RF)\", color=\"black\")\nax.bar(1, rf_results[\"high_dim_feature_pvalue\"], label=\"High-dim Feature Set (RF)\", color=\"gray\")\nax.bar(2, mv_results[\"low_dim_feature_pvalue\"], label=\"Low-dim Feature Set (MV)\", color=\"green\")\nax.bar(3, mv_results[\"high_dim_feature_pvalue\"], label=\"High-dim Feature Set (MV)\", color=\"blue\")\nax.axhline(0.05, color=\"k\", linestyle=\"--\", label=\"alpha=0.05\")\nax.set(\n    ylabel=\"Log10(PValue)\",\n    xlim=[-0.5, 3.5],\n    yscale=\"log\",\n    title=\"Signal Feature-set is Low-dimensional\",\n)\nax.legend()\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will make the informative feature-set, $X_1$, high-dimensional\nand verify that the null hypothesis is not rejected still.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_X = np.hstack(\n    (\n        signal_X,\n        rng.standard_normal(size=(n_samples, n_features_2 - signal_X.shape[1])),\n        rng.standard_normal(size=(n_samples, n_features_1 + noise_dims)),\n    )\n)\nX = _X.copy()\nn_features_ends = [n_features_2, X.shape[1]]\nprint(\"\\n\\nSetting important feature-set to be high-dimensional.\")\nprint(X.shape, n_features_ends)\n\nest = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=MultiViewDecisionTreeClassifier(\n            feature_set_ends=n_features_ends,\n            apply_max_features_per_feature_set=True,\n        ),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n)\n\nrf_est = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=DecisionTreeClassifier(),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n)\n\nmv_results = dict()\nrf_results = dict()\n\n# we test for the first feature set, which is lower-dimensional\ncovariate_index = np.arange(n_features_ends[0], dtype=int)\nstat, pvalue = est.test(X, y, covariate_index=covariate_index, metric=\"mi\", n_repeats=n_repeats)\n\nmv_results[\"high_dim_feature_stat\"] = stat\nmv_results[\"high_dim_feature_pvalue\"] = pvalue\nprint(\"\\n\\nImportant feature-set is high-dimensional\")\nprint(f\"Estimated MI difference with first view (has dependency): {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is higher-dimensional\ncovariate_index = np.arange(n_features_ends[0], n_features_ends[1], dtype=int)\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=covariate_index,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nmv_results[\"low_dim_feature_stat\"] = stat\nmv_results[\"low_dim_feature_pvalue\"] = pvalue\nprint(\n    f\"Estimated MI difference testing second view (does not have dependency): \"\n    f\"{stat} with Pvalue: {pvalue}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, we compare to using a standard decision tree classifier as our base model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covariate_index = np.arange(n_features_ends[0], dtype=int)\nstat, pvalue = rf_est.test(X, y, covariate_index=covariate_index, metric=\"mi\", n_repeats=n_repeats)\n\nrf_results[\"low_dim_feature_stat\"] = stat\nrf_results[\"low_dim_feature_pvalue\"] = pvalue\nprint(\"\\n\\nComparing with random forest.\")\nprint(f\"Estimated MI difference with first view (has dependency): {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is higher-dimensional\ncovariate_index = np.arange(n_features_ends[0], n_features_ends[1], dtype=int)\nstat, pvalue = rf_est.test(\n    X,\n    y,\n    covariate_index=covariate_index,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nrf_results[\"high_dim_feature_stat\"] = stat\nrf_results[\"high_dim_feature_pvalue\"] = pvalue\nprint(\n    f\"Estimated MI difference testing second view (does not have dependency): \"\n    f\"{stat} with Pvalue: {pvalue}\"\n)\n\nfig, ax = plt.subplots(figsize=(5, 3))\n\n# plot pvalues\nax.bar(0, rf_results[\"low_dim_feature_pvalue\"], label=\"Low-dim Feature Set (RF)\", color=\"black\")\nax.bar(1, rf_results[\"high_dim_feature_pvalue\"], label=\"High-dim Feature Set (RF)\", color=\"black\")\nax.bar(2, mv_results[\"low_dim_feature_pvalue\"], label=\"Low-dim Feature Set (MV)\", color=\"green\")\nax.bar(3, mv_results[\"high_dim_feature_pvalue\"], label=\"High-dim Feature Set (MV)\", color=\"green\")\nax.axhline(0.05, color=\"k\", linestyle=\"--\", label=\"alpha=0.05\")\nax.set(\n    ylabel=\"Log10(PValue)\",\n    xlim=[-0.5, 3.5],\n    yscale=\"log\",\n    title=\"Signal Feature-set is High-dimensional\",\n)\nax.legend()\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\nWe see that when the null hypothesis is true, the multi-view decision tree does not\nreject the null hypothesis. In addition, it rejects the null hypothesis when there is\na dependency between the target and the feature-set even when the feature-set is\nhigher-dimensionality. This is in contrast to the standard decision tree, which\nfails to reject the null hypothesis when the feature-set with signal is\nhigher-dimensional.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}