{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Mutual Information for Gigantic Hypothesis Testing (MIGHT) with Imbalanced Data\n\nHere, we demonstrate how to do hypothesis testing on highly imbalanced data\nin terms of their feature-set dimensionalities.\nusing mutual information as a test statistic. We use the framework of\n:footcite:`coleman2022scalable` to estimate pvalues efficiently.\n\nHere, we simulate two feature sets, one of which is important for the target,\nbut significantly smaller in dimensionality than the other feature set, which\nis unimportant for the target. We then use the MIGHT framework to test for\nthe importance of each feature set. Instead of leveraging a normal honest random\nforest to estimate the posteriors, here we leverage a multi-view honest random\nforest, with knowledge of the multi-view structure of the ``X`` data.\n\nFor other examples of hypothesis testing, see the following:\n\n- `sphx_glr_auto_examples_hypothesis_testing_plot_MI_gigantic_hypothesis_testing_forest.py`\n- `sphx_glr_auto_examples_hypothesis_testing_plot_might_auc.py`\n\nFor more information on the multi-view decision-tree, see\n`sphx_glr_auto_examples_multiview_plot_multiview_dtc.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import make_blobs\n\nfrom sktree import HonestForestClassifier\nfrom sktree.stats import FeatureImportanceForestClassifier\nfrom sktree.tree import DecisionTreeClassifier, MultiViewDecisionTreeClassifier\n\nseed = 12345\nrng = np.random.default_rng(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate data\nWe simulate the two feature sets, and the target variable. We then combine them\ninto a single dataset to perform hypothesis testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed = 12345\nrng = np.random.default_rng(seed)\n\n\ndef make_multiview_classification(\n    n_samples=100, n_features_1=10, n_features_2=1000, cluster_std=2.0, seed=None\n):\n    rng = np.random.default_rng(seed=seed)\n\n    # Create a high-dimensional multiview dataset with a low-dimensional informative\n    # subspace in one view of the dataset.\n    X0_first, y0 = make_blobs(\n        n_samples=n_samples,\n        cluster_std=cluster_std,\n        n_features=n_features_1 // 2,\n        random_state=rng.integers(1, 10000),\n        centers=1,\n    )\n\n    X1_first, y1 = make_blobs(\n        n_samples=n_samples,\n        cluster_std=cluster_std,\n        n_features=n_features_1 // 2,\n        random_state=rng.integers(1, 10000),\n        centers=1,\n    )\n\n    # create the first views for y=0 and y=1\n    X0_first = np.concatenate(\n        (X0_first, rng.standard_normal(size=(n_samples, n_features_1 // 2))), axis=1\n    )\n    X1_first = np.concatenate(\n        (X1_first, rng.standard_normal(size=(n_samples, n_features_1 // 2))), axis=1\n    )\n    y1[:] = 1\n\n    # add the second view for y=0 and y=1, which is completely noise\n    X0 = np.concatenate([X0_first, rng.standard_normal(size=(n_samples, n_features_2))], axis=1)\n    X1 = np.concatenate([X1_first, rng.standard_normal(size=(n_samples, n_features_2))], axis=1)\n\n    # combine the views and targets\n    X = np.vstack((X0, X1))\n    y = np.hstack((y0, y1)).T\n\n    # add noise to the data\n    X = X + rng.standard_normal(size=X.shape)\n\n    return X, y\n\n\nn_samples = 100\nn_features = 10000\nn_features_views = [10, n_features]\n\nX, y = make_multiview_classification(\n    n_samples=n_samples,\n    n_features_1=10,\n    n_features_2=n_features,\n    cluster_std=2.0,\n    seed=seed,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform hypothesis testing using Mutual Information\nHere, we use :class:`~sktree.stats.FeatureImportanceForestClassifier` to perform the hypothesis\ntest. The test statistic is computed by comparing the metric (i.e. mutual information) estimated\nbetween two forests. One forest is trained on the original dataset, and one forest is trained\non a permuted dataset, where the rows of the ``covariate_index`` columns are shuffled randomly.\n\nThe null distribution is then estimated in an efficient manner using the framework of\n:footcite:`coleman2022scalable`. The sample evaluations of each forest (i.e. the posteriors)\nare sampled randomly ``n_repeats`` times to generate a null distribution. The pvalue is then\ncomputed as the proportion of samples in the null distribution that are less than the\nobserved test statistic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_estimators = 200\nmax_features = \"sqrt\"\ntest_size = 0.2\nn_repeats = 1000\nn_jobs = -1\n\nest = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=MultiViewDecisionTreeClassifier(feature_set_ends=n_features_views),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n    permute_per_tree=False,\n    sample_dataset_per_tree=False,\n)\n\nmv_results = dict()\n\nprint(\n    f\"Permutation per tree: {est.permute_per_tree} and sampling dataset per tree: \"\n    f\"{est.sample_dataset_per_tree}\"\n)\n# we test for the first feature set, which is important and thus should return a pvalue < 0.05\nstat, pvalue = est.test(\n    X, y, covariate_index=np.arange(10, dtype=int), metric=\"mi\", n_repeats=n_repeats\n)\nmv_results[\"important_feature_stat\"] = stat\nmv_results[\"important_feature_pvalue\"] = pvalue\nprint(f\"Estimated MI difference: {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is unimportant and thus should return a pvalue > 0.05\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=np.arange(10, n_features, dtype=int),\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nmv_results[\"unimportant_feature_stat\"] = stat\nmv_results[\"unimportant_feature_pvalue\"] = pvalue\nprint(f\"Estimated MI difference: {stat} with Pvalue: {pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's investigate what happens when we do not use a multi-view decision tree.\nAll other parameters are kept the same.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=DecisionTreeClassifier(),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n    permute_per_tree=False,\n    sample_dataset_per_tree=False,\n)\n\nrf_results = dict()\n\n# we test for the first feature set, which is important and thus should return a pvalue < 0.05\nstat, pvalue = est.test(\n    X, y, covariate_index=np.arange(10, dtype=int), metric=\"mi\", n_repeats=n_repeats\n)\nrf_results[\"important_feature_stat\"] = stat\nrf_results[\"important_feature_pvalue\"] = pvalue\nprint(f\"Estimated MI difference using regular decision-trees: {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is unimportant and thus should return a pvalue > 0.05\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=np.arange(10, n_features, dtype=int),\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nrf_results[\"unimportant_feature_stat\"] = stat\nrf_results[\"unimportant_feature_pvalue\"] = pvalue\nprint(f\"Estimated MI difference using regular decision-trees: {stat} with Pvalue: {pvalue}\")\n\nfig, ax = plt.subplots(figsize=(5, 3))\n\n# plot pvalues\nax.bar(0, rf_results[\"important_feature_pvalue\"], label=\"Important Feature Set (RF)\")\nax.bar(1, rf_results[\"unimportant_feature_pvalue\"], label=\"Unimportant Feature Set (RF)\")\nax.bar(2, mv_results[\"important_feature_pvalue\"], label=\"Important Feature Set (MV)\")\nax.bar(3, mv_results[\"unimportant_feature_pvalue\"], label=\"Unimportant Feature Set (MV)\")\nax.axhline(0.05, color=\"k\", linestyle=\"--\", label=\"alpha=0.05\")\nax.set(ylabel=\"Log10(PValue)\", xlim=[-0.5, 3.5], yscale=\"log\")\nax.legend()\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\nWe see that the multi-view decision tree is able to detect the important feature set,\nwhile the regular decision tree is not. This is because the regular decision tree\nis not aware of the multi-view structure of the data, and thus is challenged\nby the imbalanced dimensionality of the feature sets. I.e. it rarely splits on\nthe first low-dimensional feature set, and thus is unable to detect its importance.\n\nNote both approaches still fail to reject the null hypothesis (for alpha of 0.05)\nwhen testing the unimportant feature set. The difference in the two approaches\nshow the statistical power of the multi-view decision tree is higher than the\nregular decision tree in this simulation.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}