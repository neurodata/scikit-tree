{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demonstrate Conditional Mutual Information for Genuine Hypothesis Testing (Co-MIGHT)\n\nIn this example, we demonstrate how to test the conditional mutual information (CMI)\nhypothesis test. To perform CMI testing, we have the hypothesis test:\n\n- $H_0: I(X_2; Y | X_1) = 0$\n- $H_1: I(X_2; Y | X_1) > 0$\n\nHere, we simulate two feature-sets, which are both informative for the target. The\ndata-generating process follows the graphical model:\n\n$(X_1 \\rightarrow X_2 \\rightarrow Y; X_1 \\rightarrow Y)$\n\nThis means that $I(X_1; Y | X_2) > 0$ if we had a perfect estimate of CMI.\n\nWe will demonstrate how to perform the CMI test properly using a conditional\npermutation (compared to a standard permutation) of samples. We specifically\nexplore the case where the alternative hypothesis is true and determine when\nthe test is able to reject the null hypothesis correctly.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This does not exactly implement conditional-independence testing\n    yet, since we do not have a way to estimate the null distribution of\n    $I(X_2; Y | X_1)$. However, we can still demonstrate the power of the\n    test in the case where the alternative hypothesis is true.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import make_spd_matrix\n\nfrom sktree import HonestForestClassifier\nfrom sktree.datasets import make_gaussian_mixture\nfrom sktree.stats import FeatureImportanceForestClassifier\nfrom sktree.tree import DecisionTreeClassifier, MultiViewDecisionTreeClassifier\n\nseed = 12345\nrng = np.random.default_rng(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate data\nWe simulate the two feature sets, and the target variable. We then combine them\ninto a single dataset to perform hypothesis testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed = 12345\nrng = np.random.default_rng(seed)\n\nn_samples = 200\n\nn_features = 20\nnoise_dims = 80\nclass_probs = [0.6, 0.4]\nn_features_2 = 1000 - noise_dims\n\nfixed_center = rng.standard_normal(size=(n_features,))\ncenters = [fixed_center, fixed_center]\n\ncovariances = [\n    make_spd_matrix(n_dim=n_features, random_state=seed),\n    make_spd_matrix(n_dim=n_features, random_state=seed + 123),\n]\n\nXs, y = make_gaussian_mixture(\n    centers,\n    covariances,\n    n_samples=n_samples,\n    noise=1.0,\n    noise_dims=noise_dims,\n    shuffle=True,\n    class_probs=class_probs,\n    random_state=seed,\n    transform=\"linear\",\n)\n\nsecond_X = Xs[0]\nfirst_X = Xs[1]\n\nprint(first_X.shape, second_X.shape)\nX = np.hstack((first_X, second_X, rng.standard_normal(size=(n_samples, n_features_2 - n_features))))\nn_features_ends = [\n    n_features + noise_dims,\n    n_features_2 + n_features + noise_dims * 2,\n]\n\nprint(X.shape, y.shape, n_features_ends)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform hypothesis testing\nHere, we use :class:`~sktree.stats.FeatureImportanceForestClassifier` to perform the hypothesis\ntest. The test statistic is computed by comparing the metric (i.e. mutual information) estimated\nbetween two forests. One forest is trained on the original dataset, and one forest is trained\non a permuted dataset, where the rows of the ``covariate_index`` columns are shuffled randomly.\n\nThe null distribution is then estimated in an efficient manner using the framework of\n:footcite:`coleman2022scalable`. The sample evaluations of each forest (i.e. the posteriors)\nare sampled randomly ``n_repeats`` times to generate a null distribution. The pvalue is then\ncomputed as the proportion of samples in the null distribution that are less than the\nobserved test statistic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_estimators = 200\nmax_features = 0.3\ntest_size = 0.2\nn_repeats = 1000\nn_jobs = -1\n\nest = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=MultiViewDecisionTreeClassifier(\n            feature_set_ends=n_features_ends,\n            apply_max_features_per_feature_set=True,\n        ),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n    sample_dataset_per_tree=False,\n)\n\nmv_results = dict()\n\n# we test for the first feature set, which is lower-dimensional\ncovariate_index = np.arange(n_features_ends[0], dtype=int)\nstat, pvalue = est.test(X, y, covariate_index=covariate_index, metric=\"mi\", n_repeats=n_repeats)\n\nmv_results[\"low_dim_feature_stat\"] = stat\nmv_results[\"low_dim_feature_pvalue\"] = pvalue\nprint(\"Analysis with multi-view decision tree.\")\nprint(f\"Estimated MI difference: {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is higher-dimensional\ncovariate_index = np.arange(n_features_ends[0], n_features_ends[1], dtype=int)\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=covariate_index,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nmv_results[\"high_dim_feature_stat\"] = stat\nmv_results[\"high_dim_feature_pvalue\"] = pvalue\nprint(f\"Estimated MI difference: {stat} with Pvalue: {pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's investigate what happens when we do not use a multi-view decision tree.\nAll other parameters are kept the same.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=DecisionTreeClassifier(),\n        random_state=seed,\n        honest_fraction=0.5,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n    sample_dataset_per_tree=False,\n)\n\nrf_results = dict()\n\n# we test for the first feature set, which is lower-dimensional\ncovariate_index = np.arange(n_features_ends[0], dtype=int)\nstat, pvalue = est.test(X, y, covariate_index=covariate_index, metric=\"mi\", n_repeats=n_repeats)\n\nrf_results[\"low_dim_feature_stat\"] = stat\nrf_results[\"low_dim_feature_pvalue\"] = pvalue\nprint(\"\\n\\nAnalysing now with a regular decision-tree\")\nprint(f\"Estimated MI difference using regular decision-trees: {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is higher-dimensional\ncovariate_index = np.arange(n_features_ends[0], n_features_ends[1], dtype=int)\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=covariate_index,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nrf_results[\"high_dim_feature_stat\"] = stat\nrf_results[\"high_dim_feature_pvalue\"] = pvalue\nprint(f\"Estimated MI difference using regular decision-trees: {stat} with Pvalue: {pvalue}\")\n\nfig, ax = plt.subplots(figsize=(5, 3))\n\n# plot pvalues\nax.bar(0, rf_results[\"low_dim_feature_pvalue\"], label=\"Low-dim Feature Set (RF)\")\nax.bar(1, rf_results[\"high_dim_feature_pvalue\"], label=\"High-dim Feature Set (RF)\")\nax.bar(2, mv_results[\"low_dim_feature_pvalue\"], label=\"Low-dim Feature Set (MV)\")\nax.bar(3, mv_results[\"high_dim_feature_pvalue\"], label=\"High-dim Feature Set (MV)\")\nax.axhline(0.05, color=\"k\", linestyle=\"--\", label=\"alpha=0.05\")\nax.set(ylabel=\"Log10(PValue)\", xlim=[-0.5, 3.5], yscale=\"log\")\nax.legend()\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\nIn this example, since both feature-sets are in informative for the target, the true\nanswer should be reject the null hypothesis. We see that neither the regular decision\ntree, nor the multi-view decision tree is able to reject the null hypothesis correctly.\n\nHowever, if we permute the lower-dimensional feature-set, the multi-view decision tree\nhas a lower pvalue than the regular decision tree, which allows us to correctly\nreject the null hypothesis at lower $\\alpha$ levels.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}