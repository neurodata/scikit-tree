{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Mutual Information for Gigantic Hypothesis Testing (MIGHT)\n\nAn example using :class:`~sktree.stats.FeatureImportanceForestClassifier` for nonparametric\nmultivariate hypothesis test, on simulated datasets. Here, we present a simulation\nof how MIGHT is used to test the hypothesis that a \"feature set is important for\npredicting the target\". This is a generalization of the framework presented in\n:footcite:`coleman2022scalable`.\n\nWe simulate a dataset with 1000 features, 500 samples, and a binary class target\nvariable. Within each feature set, there is 500 features associated with one feature\nset, and another 500 features associated with another feature set. One could think of\nthese for example as different datasets collected on the same patient in a biomedical setting.\nThe first feature set (X) is strongly correlated with the target, and the second\nfeature set (W) is weakly correlated with the target (y). Here, we are testing the\nnull hypothesis:\n\n- ``H0: I(X; y) - I(X, W; y) = 0``\n- ``HA: I(X; y) - I(X, W; y) < 0`` indicating that there is more mutual information with\n    respect to ``y``\n\nwhere ``I`` is mutual information. For example, this could be true in the following settings,\nwhere X is our informative feature set and W is our uninformative feature set.\n\n- ``W    X -> y``: here ``W`` is completely disconnected from X and y.\n- ``W -> X -> y``: here ``W`` is d-separated from y given X.\n- ``W <- X -> y``: here ``W`` is d-separated from y given X.\n\nWe then use MIGHT to test the hypothesis that the first feature set is important for\npredicting the target, and the second feature set is not important for predicting the\ntarget. We use :class:`~sktree.stats.FeatureImportanceForestClassifier`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom scipy.special import expit\n\nfrom sktree import HonestForestClassifier\nfrom sktree.stats import FeatureImportanceForestClassifier\nfrom sktree.tree import DecisionTreeClassifier\n\nseed = 12345\nrng = np.random.default_rng(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate data\nWe simulate the two feature sets, and the target variable. We then combine them\ninto a single dataset to perform hypothesis testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 1000\nn_features_set = 500\nmean = 1.0\nsigma = 2.0\nbeta = 5.0\n\nunimportant_mean = 0.0\nunimportant_sigma = 4.5\n\n# first sample the informative features, and then the uniformative features\nX_important = rng.normal(loc=mean, scale=sigma, size=(n_samples, 10))\nX_important = np.hstack(\n    [\n        X_important,\n        rng.normal(\n            loc=unimportant_mean, scale=unimportant_sigma, size=(n_samples, n_features_set - 10)\n        ),\n    ]\n)\n\nX_unimportant = rng.normal(\n    loc=unimportant_mean, scale=unimportant_sigma, size=(n_samples, n_features_set)\n)\nX = np.hstack([X_important, X_unimportant])\n\n# simulate the binary target variable\ny = rng.binomial(n=1, p=expit(beta * X_important[:, :10].sum(axis=1)), size=n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform hypothesis testing using Mutual Information\nHere, we use :class:`~sktree.stats.FeatureImportanceForestClassifier` to perform the hypothesis\ntest. The test statistic is computed by comparing the metric (i.e. mutual information) estimated\nbetween two forests. One forest is trained on the original dataset, and one forest is trained\non a permuted dataset, where the rows of the ``covariate_index`` columns are shuffled randomly.\n\nThe null distribution is then estimated in an efficient manner using the framework of\n:footcite:`coleman2022scalable`. The sample evaluations of each forest (i.e. the posteriors)\nare sampled randomly ``n_repeats`` times to generate a null distribution. The pvalue is then\ncomputed as the proportion of samples in the null distribution that are less than the\nobserved test statistic.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_estimators = 200\nmax_features = \"sqrt\"\ntest_size = 0.2\nn_repeats = 1000\nn_jobs = -1\n\nest = FeatureImportanceForestClassifier(\n    estimator=HonestForestClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        tree_estimator=DecisionTreeClassifier(),\n        random_state=seed,\n        honest_fraction=0.7,\n        n_jobs=n_jobs,\n    ),\n    random_state=seed,\n    test_size=test_size,\n    permute_per_tree=True,\n    sample_dataset_per_tree=False,\n)\n\nprint(\n    f\"Permutation per tree: {est.permute_per_tree} and sampling dataset per tree: \"\n    f\"{est.sample_dataset_per_tree}\"\n)\n# we test for the first feature set, which is important and thus should return a pvalue < 0.05\nstat, pvalue = est.test(\n    X, y, covariate_index=np.arange(n_features_set, dtype=int), metric=\"mi\", n_repeats=n_repeats\n)\nprint(f\"Estimated MI difference: {stat} with Pvalue: {pvalue}\")\n\n# we test for the second feature set, which is unimportant and thus should return a pvalue > 0.05\nstat, pvalue = est.test(\n    X,\n    y,\n    covariate_index=np.arange(n_features_set, dtype=int) + n_features_set,\n    metric=\"mi\",\n    n_repeats=n_repeats,\n)\nprint(f\"Estimated MI difference: {stat} with Pvalue: {pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}